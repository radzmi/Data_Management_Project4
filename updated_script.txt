# -*- coding: utf-8 -*-

from pyspark.sql import SparkSession
from pyspark.sql import Row
from pyspark.sql import functions as F

def parse_user_input(line):
    fields = line.split('|')
    return Row(user_id=int(fields[0]), age=int(fields[1]), gender=fields[2], occupation=fields[3], zip=fields[4])

def parse_rating_input(line):
    fields = line.split('\t')
    return Row(user_id=int(fields[0]), item_id=int(fields[1]), rating=int(fields[2]), timestamp=int(fields[3]))

def parse_movie_input(line):
    fields = line.split('|')
    genres = fields[5:]  # Genres start from the 6th field
    genre_list = ['unknown', 'Action', 'Adventure', 'Animation', "Children's", 'Comedy', 'Crime', 'Documentary', 
                  'Drama', 'Fantasy', 'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 
                  'Thriller', 'War', 'Western']
    genre_dict = {genre: int(flag) for genre, flag in zip(genre_list, genres)}
    return Row(item_id=int(fields[0]), title=fields[1], genres=genre_dict)

if __name__ == "__main__":
    # Create a SparkSession
    spark = SparkSession.builder \
        .appName("CassandraIntegration") \
        .config("spark.cassandra.connection.host", "127.0.0.1") \
        .getOrCreate()

    # Load user data
    user_lines = spark.sparkContext.textFile("hdfs:///user/maria_dev/ml-100k/u.user")
    users = user_lines.map(parse_user_input)
    users_df = spark.createDataFrame(users)

    # Write user data into Cassandra
    users_df.write \
        .format("org.apache.spark.sql.cassandra") \
        .mode('append') \
        .options(table="users", keyspace="movielens") \
        .save()

    # Load rating data
    rating_lines = spark.sparkContext.textFile("hdfs:///user/maria_dev/ml-100k/u.data")
    ratings = rating_lines.map(parse_rating_input)
    ratings_df = spark.createDataFrame(ratings)

    # Write rating data into Cassandra
    ratings_df.write \
        .format("org.apache.spark.sql.cassandra") \
        .mode('append') \
        .options(table="ratings", keyspace="movielens") \
        .save()

    # Load movie data
    movie_lines = spark.sparkContext.textFile("hdfs:///user/maria_dev/ml-100k/u.item")
    movies = movie_lines.map(parse_movie_input)
    movies_df = spark.createDataFrame(movies)

    # Write movie data into Cassandra
    movies_df.write \
        .format("org.apache.spark.sql.cassandra") \
        .mode('append') \
        .options(table="movies", keyspace="movielens") \
        .save()

    # Read data back from Cassandra
    users_df = spark.read \
        .format("org.apache.spark.sql.cassandra") \
        .options(table="users", keyspace="movielens") \
        .load()

    ratings_df = spark.read \
        .format("org.apache.spark.sql.cassandra") \
        .options(table="ratings", keyspace="movielens") \
        .load()

    movies_df = spark.read \
        .format("org.apache.spark.sql.cassandra") \
        .options(table="movies", keyspace="movielens") \
        .load()

    # Create temporary views for SQL queries
    users_df.createOrReplaceTempView("users")
    ratings_df.createOrReplaceTempView("ratings")
    movies_df.createOrReplaceTempView("movies")

    # i) Calculate the average rating for each movie
    avg_ratings_df = spark.sql("""
        SELECT item_id, AVG(rating) as avg_rating
        FROM ratings
        GROUP BY item_id
    """)
    avg_ratings_df.createOrReplaceTempView("avg_ratings")
    avg_ratings_df.show(10)

    # ii) Identify the top ten movies with the highest average ratings
    top_movies_df = spark.sql("""
        SELECT m.title, ar.avg_rating
        FROM avg_ratings ar
        JOIN movies m ON ar.item_id = m.item_id
        ORDER BY ar.avg_rating DESC
        LIMIT 10
    """)
    top_movies_df.show()

    # iii) Find the users who have rated at least 50 movies and identify their favourite movie genres
    user_ratings_count_df = spark.sql("""
        SELECT user_id, COUNT(item_id) as movie_count
        FROM ratings
        GROUP BY user_id
        HAVING movie_count >= 50
    """)
    user_ratings_count_df.createOrReplaceTempView("active_users")

    favourite_genres_df = spark.sql("""
        SELECT au.user_id, u.age, u.gender, u.occupation, u.zip,
               inline(arrays_zip(
                   explode(array('unknown', 'Action', 'Adventure', 'Animation', 'Children\'s', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western')),
                   explode(array(
                       SUM(CASE WHEN m.genres['unknown'] = 1 THEN 1 ELSE 0 END) as unknown,
                       SUM(CASE WHEN m.genres['Action'] = 1 THEN 1 ELSE 0 END) as Action,
                       SUM(CASE WHEN m.genres['Adventure'] = 1 THEN 1 ELSE 0 END) as Adventure,
                       SUM(CASE WHEN m.genres['Animation'] = 1 THEN 1 ELSE 0 END) as Animation,
                       SUM(CASE WHEN m.genres['Children\'s'] = 1 THEN 1 ELSE 0 END) as Childrens,
                       SUM(CASE WHEN m.genres['Comedy'] = 1 THEN 1 ELSE 0 END) as Comedy,
                       SUM(CASE WHEN m.genres['Crime'] = 1 THEN 1 ELSE 0 END) as Crime,
                       SUM(CASE WHEN m.genres['Documentary'] = 1 THEN 1 ELSE 0 END) as Documentary,
                       SUM(CASE WHEN m.genres['Drama'] = 1 THEN 1 ELSE 0 END) as Drama,
                       SUM(CASE WHEN m.genres['Fantasy'] = 1 THEN 1 ELSE 0 END) as Fantasy,
                       SUM(CASE WHEN m.genres['Film-Noir'] = 1 THEN 1 ELSE 0 END) as FilmNoir,
                       SUM(CASE WHEN m.genres['Horror'] = 1 THEN 1 ELSE 0 END) as Horror,
                       SUM(CASE WHEN m.genres['Musical'] = 1 THEN 1 ELSE 0 END) as Musical,
                       SUM(CASE WHEN m.genres['Mystery'] = 1 THEN 1 ELSE 0 END) as Mystery,
                       SUM(CASE WHEN m.genres['Romance'] = 1 THEN 1 ELSE 0 END) as Romance,
                       SUM(CASE WHEN m.genres['Sci-Fi'] = 1 THEN 1 ELSE 0 END) as SciFi,
                       SUM(CASE WHEN m.genres['Thriller'] = 1 THEN 1 ELSE 0 END) as Thriller,
                       SUM(CASE WHEN m.genres['War'] = 1 THEN 1 ELSE 0 END) as War,
                       SUM(CASE WHEN m.genres['Western'] = 1 THEN 1 ELSE 0 END) as Western
                   ))
               )) as genre, count
        FROM active_users au
        JOIN ratings r ON au.user_id = r.user_id
        JOIN movies m ON r.item_id = m.item_id
        JOIN users u ON au.user_id = u.user_id
        GROUP BY au.user_id, u.age, u.gender, u.occupation, u.zip
        ORDER BY au.user_id, count DESC
    """).select("user_id", "age", "gender", "occupation", "zip", "genre", "count")

    favourite_genres_df.createOrReplaceTempView("favourite_genres")

    top_favourite_genres_df = spark.sql("""
        SELECT user_id, age, gender, occupation, zip, genre, count
        FROM (
            SELECT *, ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY count DESC) as row_number
            FROM favourite_genres
        ) tmp
        WHERE row_number = 1
    """)

    top_favourite_genres_df.show(10)

    # iv) Find all the users with age that is less than 20 years old
    young_users_df = spark.sql("SELECT * FROM users WHERE age < 20")
    young_users_df.show(10)

    # v) Find all the users who have the occupation “scientist” and their age is between 30 and 40 years old
    scientists_df = spark.sql("SELECT * FROM users WHERE occupation = 'scientist' AND age BETWEEN 30 AND 40")
    scientists_df.show(10)

    # Stop the session
    spark.stop()
